# ๐ค ุชุซุจูุช ูุชุดุบูู Ollama

## ุงููุดููุฉ ุงูุญุงููุฉ
```
cURL error 7: Failed to connect to localhost port 11434
```
ูุฐุง ูุนูู ุฃู Ollama ุบูุฑ ุดุบุงู ุฃู ุบูุฑ ูุซุจุช.

---

## โ ุงูุญู: ุชุซุจูุช ูุชุดุบูู Ollama

### 1. ุชุญููู Ollama

**ููู Windows:**
1. ุงูุชุญ ุงูุฑุงุจุท: https://ollama.com/download/windows
2. ุญููู ููู `OllamaSetup.exe`
3. ุดุบูู ุงูููู ูุงุชุจุน ุฎุทูุงุช ุงูุชุซุจูุช

**ุฃู ุจุงุณุชุฎุฏุงู PowerShell:**
```powershell
# Download and install
irm https://ollama.com/install.ps1 | iex
```

---

### 2. ุชุดุบูู Ollama

ุจุนุฏ ุงูุชุซุจูุชุ ุงูุชุญ **Command Prompt** ุฃู **PowerShell** ูุดุบูู:

```bash
ollama serve
```

**ูุฌุจ ุฃู ุชุฑู ุฑุณุงูุฉ:**
```
Listening on 127.0.0.1:11434
```

---

### 3. ุชุญููู Model (Gemma 2B)

**ูู ูุงูุฐุฉ CMD ุฌุฏูุฏุฉ** (ุงุชุฑู ุงูุฃููู ุดุบุงูุฉ)ุ ุดุบูู:

```bash
ollama pull gemma:2b
```

**ุณูุจุฏุฃ ุงูุชุญููู:**
```
pulling manifest
pulling 8ccb135d64b4... 100% โโโโโโโโโโโโโโ 1.6 GB
pulling 966de95ca8a6... 100% โโโโโโโโโโโโโโ   485 B
pulling faffde1eaecb... 100% โโโโโโโโโโโโโโ   342 B
pulling 1d3d775a0bf5... 100% โโโโโโโโโโโโโโ   106 B
pulling f02dd72bb242... 100% โโโโโโโโโโโโโโ    59 B
verifying sha256 digest
writing manifest
removing any unused layers
success
```

**ุงูุชุธุฑ ุญุชู ููุชูู ุงูุชุญููู (ุญูุงูู 1.6 GB)**

---

### 4. ุงุฎุชุจุงุฑ Ollama

ุจุนุฏ ุงูุชุญูููุ ุงุฎุชุจุฑ ุฃู ุงูู model ูุนูู:

```bash
ollama run gemma:2b "ูุฑุญุจุงู"
```

**ูุฌุจ ุฃู ุชุฑู ุฑุฏ ูู ุงูู AI**

---

### 5. ุงูุชุญูู ูู ุนูู Ollama API

**ูู CMD:**
```bash
curl http://localhost:11434/api/tags
```

**ูุฌุจ ุฃู ุชุฑู:**
```json
{
  "models": [
    {
      "name": "gemma:2b",
      "model": "gemma:2b",
      ...
    }
  ]
}
```

---

## ๐ ุงุณุชุฎุฏุงู ุงูุชุทุจูู ุงูุขู

ุจุนุฏ ุชุดุบูู Ollama:

1. **ุชุฃูุฏ ุฃู Ollama ุดุบุงู:**
   ```bash
   ollama serve
   ```
   (ุงุชุฑู ูุฐู ุงููุงูุฐุฉ ููุชูุญุฉ)

2. **ุงูุชุญ ุงููุชุตูุญ:**
   ```
   http://127.0.0.1:8000/wizard/start
   ```

3. **ุงุถุบุท "ุชูููุฏ ุจุงูุฐูุงุก ุงูุงุตุทูุงุนู"**
   - ุงูุขู ุณูุนูู ุจุฏูู ุฃุฎุทุงุก!

---

## ๐ Models ุงููุชุงุญุฉ

ููููู ุงุณุชุฎุฏุงู models ุฃุฎุฑู:

### Models ุตุบูุฑุฉ (ุณุฑูุนุฉ):
```bash
ollama pull gemma:2b      # 1.6 GB - ุณุฑูุน ุฌุฏุงู
ollama pull phi3:mini     # 2.3 GB - ุฌูุฏ ูููุตูุต ุงููุตูุฑุฉ
ollama pull llama3.2:1b   # 1.3 GB - ุงูุฃุฎู ูุงูุฃุณุฑุน
```

### Models ูุชูุณุทุฉ (ููุงุฒูุฉ):
```bash
ollama pull llama3.2:3b   # 2.0 GB - ููุชุงุฒ ูููุตูุต ุงูุทูููุฉ
ollama pull mistral:7b    # 4.1 GB - ููู ููุชูุงุฒู
```

### Models ูุจูุฑุฉ (ุฏูุฉ ุนุงููุฉ):
```bash
ollama pull llama3:8b     # 4.7 GB - ุฌูุฏุฉ ููุชุงุฒุฉ
ollama pull llama3:70b    # 40 GB - ุงูุฃูุถู (ูุญุชุงุฌ GPU ููู)
```

---

## โ๏ธ ุชุบููุฑ ุงูู Model ูู ุงูุชุทุจูู

**ุงูุชุญ ููู:**
```
wave-app/config/ollama.php
```

**ุบููุฑ ุงูุณุทุฑ 18:**
```php
'default_model' => env('OLLAMA_MODEL', 'gemma:2b'),
```

**ุฅูู:**
```php
'default_model' => env('OLLAMA_MODEL', 'llama3.2:3b'),  // ุฃู ุฃู model ุขุฎุฑ
```

---

## ๐ง ุงุณุชูุดุงู ุงูุฃุฎุทุงุก

### ุงููุดููุฉ: "connection refused"
**ุงูุญู:**
```bash
# ุชุฃูุฏ ุฃู Ollama ุดุบุงู
ollama serve
```

### ุงููุดููุฉ: "model not found"
**ุงูุญู:**
```bash
# ุชุญูู ูู ุงูู models ุงููุซุจุชุฉ
ollama list

# ุญููู ุงูู model
ollama pull gemma:2b
```

### ุงููุดููุฉ: ุจุทุก ูู ุงูุชูููุฏ
**ุงูุญู:**
1. ุงุณุชุฎุฏู model ุฃุตุบุฑ (gemma:2b ุฃู llama3.2:1b)
2. ููู `max_tokens` ูู `config/ollama.php`
3. ุงุณุชุฎุฏู GPU ุฅุฐุง ูุชููุฑ

---

## ๐ ููุงุฑูุฉ Models

| Model | Size | Speed | Quality | Use Case |
|-------|------|-------|---------|----------|
| llama3.2:1b | 1.3 GB | โญโญโญโญโญ | โญโญโญ | ูุตูุต ูุตูุฑุฉ |
| gemma:2b | 1.6 GB | โญโญโญโญโญ | โญโญโญโญ | ูุชูุงุฒู |
| llama3.2:3b | 2.0 GB | โญโญโญโญ | โญโญโญโญ | ุฎุทุท ุฃุนูุงู |
| mistral:7b | 4.1 GB | โญโญโญ | โญโญโญโญโญ | ูุตูุต ุทูููุฉ |
| llama3:8b | 4.7 GB | โญโญโญ | โญโญโญโญโญ | ุฌูุฏุฉ ุนุงููุฉ |

---

## ๐ฏ ุงูุชูุตูุฉ

**ููุจุฏุก ุงูุณุฑูุน:**
```bash
ollama pull gemma:2b
```

**ููุฌูุฏุฉ ุงูุฃูุถู:**
```bash
ollama pull llama3.2:3b
```

---

## โ ุงูุฎุทูุงุช ุงูููุงุฆูุฉ

1. โ ุญููู Ollama ูู https://ollama.com/download
2. โ ุซุจูุช Ollama
3. โ ุดุบูู `ollama serve`
4. โ ุญููู model: `ollama pull gemma:2b`
5. โ ุงุฎุชุจุฑ: `ollama run gemma:2b "ูุฑุญุจุงู"`
6. โ ุงุณุชุฎุฏู ุงูุชุทุจูู!

---

## ๐ ุงูุฏุนู

ุฅุฐุง ูุงุฌูุช ูุดุงูู:
- Ollama Docs: https://ollama.com/docs
- GitHub: https://github.com/ollama/ollama

**ููุงุญุธุฉ:** ุงุชุฑู ูุงูุฐุฉ `ollama serve` ููุชูุญุฉ ุทูู ูุชุฑุฉ ุงุณุชุฎุฏุงู ุงูุชุทุจูู.
